---
title: "Homework"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
library(tidyverse)
```



# Learning Objectives

* Clean up a dataset with common errors, outliers and missing values
* Do some summary stats

# Introduction: World Bank Data. 

The dataset we will use for this lab is part of the World Bank Data project. Specifically, we are using the "Women in Parliament" dataset, which includes the percentage of women in parliament (“single or lower parliamentary chambers only”) by country (region) and year. [Full details can be found here](https://data.worldbank.org/indicator/SG.GEN.PARL.ZS). 

We have already download the data and saved it as a .csv file called `women_in_gov` for you. This particular dataset contains everything we have covered today: metadata in the file, character and numeric variables, untidy data, and missing values. 


# MVP Task 

<br>

# Question 1 
Load in the `women_in_gov` csv file. Make sure you remove all metadata from the top. 

***

# Question 2
Some of the column names contain spaces and numbers. Fix the column names. 


***


# Question 3
We have some columns in the data that don't really need to  be there. Confirm that the `X64`, `Indicator.Name` and `Indicator.Code` have the same values for all observations. If they do, remove those columns. 


***


# Question 4
Think back to yesterday where we talked about wide vs long format. As the data is in wide format, it's pretty clear to see we have a lot of missing values. Reshape the data from wide to long format, so that for each country the year column becomes a row. Name the column you put your values into (i.e. the 'values_into' argument) `prop_women`. 


</details>
<br>

***

# Question 5
You'll notice your `prop_women` column contains missing values. Let's do a few things. First, let's count how many missing values you have. Then check how many different missing values you have (e.g. how many unique ones do you have). Then decide how you will deal with them. Will you insert average imputation values, most common imputation values, or use the multiple imputation method? Explain your decision. Then fix the missing values.   


***

# Question 6
Create a boxplot to see if there are any outliers in the proportion of women.


***

# Question 7
Use the `outliers` package to calculate a zscore for each observation in your data. Mark any of the values in the `prop_women` column that are more or less than 3 standard deviations above or below the mean as outliers. Add this outlier flag as a new column within the dataset. Create a table that only contains the outliers and have a look at them. 


***

# Question 8 
Next decide - what will you do with these outliers? Create a table with your newly dealt with outliers. 


***

# Question 9 
Now you have your clean dataset, let's do some summarising. Find the top 10 countries with the highest mean proportion of women in government across all the years. Then find the bottom 10.


***

# Question 10 

Pick another interesting analysis question of your choosing. Tell us WHY you think it is interesting, how you did it, and what it tells us.


<br>

# Extension task

There is another dataset available from the Brazil House of Deputies that we haven't analysed. This is the `deputies_info.csv` file. 

Complete the following task: 

We will be looking for outliers and relationships between the `receipt_description` variable and the `receipt_value` variable. 
Load in the data. Check the variable names, and check for missing values in the variable of interest `receipt_value`.  
Spend some time visualizing any outliers in the `receipt_value` column. Does it have a relationship with the `receipt_description` column?  
Identify which rows in the `receipt_value` column of data_v1 dataset are outliers. Try plotting them or looking through just the outliers.   
Calculate the outlier zcores for the `receipt_value` column. Replot the data, and then decide what you want to do with the outliers. 
Finally, which parties have the highest dodgy claims? What do they claim the most on?





